{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importes e bibliotecas"
      ],
      "metadata": {
        "id": "RBF3_NSXGtHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers \n",
        "!python -m spacy download pt"
      ],
      "metadata": {
        "id": "S-4H3Bp1_m4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d681c2-5e72-429f-d4d5-e29538198f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2 MB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importes de bibliotecas \n",
        "import spacy\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "# modelos pré treinados para fazer a tradução para o inglês \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")"
      ],
      "metadata": {
        "id": "DXR10Gsf8eUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# declarando qual a linguagem que o spacy vai trabalhar \n",
        "nlp = spacy.load('pt')\n",
        "# coding: utf-8"
      ],
      "metadata": {
        "id": "OhrI8eMLGCQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raciocínio Baseado em Casos"
      ],
      "metadata": {
        "id": "bGWaHSfrGwlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação dos valores dos atributos conforme frase"
      ],
      "metadata": {
        "id": "QNQjtcrmJ8ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avaliacao_atributos(frase):  \n",
        "  # lista que vai guardar a relacao dos atributos com a frase \n",
        "  lista = []\n",
        "\n",
        "  # padronizacoes \n",
        "  frase_mod = frase.lower()\n",
        "  doc = nlp(frase_mod)\n",
        "  frase_mod = [token.orth_ for token in doc] # para se assegurar que as pontuacoes\n",
        "                                            # terão um index reservado no split()   \n",
        "\n",
        "  # traducao para os atributos 4 e 5\n",
        "  pten_pipeline = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
        "  trad = pten_pipeline(frase)\n",
        "  traducao = (trad[0]['generated_text']).lower()\n",
        "\n",
        "  # Primeiro atributo - Está no final da frase?\n",
        "  ultima_palavra = frase_mod[len(frase_mod)-2]\n",
        "  if(ultima_palavra == 'que' or ultima_palavra == 'porque' or ultima_palavra == 'porquê' or ultima_palavra == 'quê'):\n",
        "    lista.append(1)\n",
        "  else:\n",
        "    lista.append(0)\n",
        "\n",
        "  # Segundo atributo - É antecido por um artigo como “o, os, um, uns”?\n",
        "  for i in range(0,len(frase_mod)):\n",
        "    if(frase_mod[i]=='porque' or \n",
        "      frase_mod[i]=='porquê' or \n",
        "      (frase_mod[i]=='por' and frase_mod[i+1] == 'quê') or \n",
        "      (frase_mod[i]=='por' and frase_mod[i+1] == 'que')):\n",
        "      if(frase_mod[i-1]=='o' or frase_mod[i-1]=='os' or frase_mod[i-1]=='um' or frase_mod[i-1]=='uns'):\n",
        "        lista.append(1)\n",
        "      else:\n",
        "        lista.append(0)\n",
        "\n",
        "  # Terceiro atributo - É antecedido por um substantivo? \n",
        "  morfologia = [token.pos_ for token in doc] # pos = parts of speech\n",
        "  for i in range(0,len(frase_mod)):\n",
        "    if(frase_mod[i]=='porque' or \n",
        "      frase_mod[i]=='porquê' or \n",
        "      (frase_mod[i]=='por' and frase_mod[i+1] == 'quê') or \n",
        "      (frase_mod[i]=='por' and frase_mod[i+1] == 'que')):\n",
        "      if(morfologia[i-1]=='NOUN'):\n",
        "        lista.append(1)\n",
        "      else:\n",
        "        lista.append(0) \n",
        "\n",
        "  # Quarto atributo - Pode ser substituído por “pois”?\n",
        "  if ('because' in traducao):\n",
        "    lista.append(1)\n",
        "  else:\n",
        "    lista.append(0)\n",
        "\n",
        "  # Quinto atributo - Pode ser substuído por “por qual motivo”?\n",
        "  if ('why' in traducao):\n",
        "    lista.append(1)\n",
        "  else:\n",
        "    lista.append(0)\n",
        "  \n",
        "  return lista"
      ],
      "metadata": {
        "id": "nlbhgUh4qRzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação dos casos bases"
      ],
      "metadata": {
        "id": "C5iwUBXnKXQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caso 1 - Por que (em perguntas)\n",
        "por_que1 = avaliacao_atributos('João, por que você brigou com sua mãe?')\n",
        "print('CASO 1 - POR QUE - ', por_que1)\n",
        "\n",
        "# Caso 2 - Por que (em frases afirmativas)\n",
        "por_que2 = avaliacao_atributos('Não achei o caminho por que passei.')\n",
        "print('CASO 2 - POR QUE - ', por_que2)\n",
        "\n",
        "# Caso 3 - Por quê\n",
        "por_que3 = avaliacao_atributos('Você não comeu por quê?')\n",
        "print('CASO 3 - POR QUÊ - ', por_que3)\n",
        "\n",
        "# Caso 4 - Porquê\n",
        "porque1 = avaliacao_atributos('Nunca vou lhe dizer o porquê da minha beleza.')\n",
        "print('CASO 4 - PORQUÊ - ', porque1)\n",
        "\n",
        "# Caso 5 - Porque\n",
        "porque2 = avaliacao_atributos('Eu sou feliz porque já fui triste.')\n",
        "print('CASO 5 - PORQUE - ', porque2)\n",
        "\n",
        "todos_casos = [por_que1, por_que2, por_que3, porque1, porque2]\n",
        "casos = ['por que','por que', 'por quê', 'porquê', 'porque']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryZp0Pz7KkBI",
        "outputId": "31e719cc-7d40-40dc-d6f5-3f5bce019883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CASO 1 - POR QUE -  [0, 0, 0, 0, 1]\n",
            "CASO 2 - POR QUE -  [0, 0, 1, 0, 0]\n",
            "CASO 3 - POR QUÊ -  [1, 0, 0, 0, 1]\n",
            "CASO 4 - PORQUÊ -  [0, 1, 0, 0, 0]\n",
            "CASO 5 - PORQUE -  [0, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cálculo das similaridades com o novo caso "
      ],
      "metadata": {
        "id": "9EKpLrTaKHny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculo_similaridade(lista):\n",
        "  sim_global = [0.0,0.0,0.0,0.0,0.0]\n",
        "  for i in range(len(lista)):\n",
        "    for j in range(len(todos_casos)):\n",
        "      if(lista[i]==todos_casos[j][i]):\n",
        "        if(i==0):\n",
        "          sim_global[j]+=3\n",
        "        elif(i==1):\n",
        "          sim_global[j]+=5\n",
        "        elif(i==2):\n",
        "          sim_global[j]+=2\n",
        "        elif(i==3):\n",
        "          sim_global[j]+=1\n",
        "        elif(i==4):\n",
        "          sim_global[j]+=1\n",
        "  sim_global = [number/12 for number in sim_global]\n",
        "  #print(sim_global)\n",
        "  caso = sim_global.index(max(sim_global))\n",
        "  porque = casos[caso] \n",
        "  return porque "
      ],
      "metadata": {
        "id": "GSPzwJCuJ21m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def palavra_porque(frase):\n",
        "  frase_mod = frase.lower()\n",
        "  doc = nlp(frase_mod)\n",
        "  frase_mod = [token.orth_ for token in doc]\n",
        "  porque = ''                      \n",
        "  for i in range(0,len(frase_mod)):\n",
        "    if(frase_mod[i]=='porque' or\n",
        "      frase_mod[i]=='porquê'):\n",
        "      porque = frase_mod[i]\n",
        "    elif((frase_mod[i]=='por' and frase_mod[i+1] == 'quê') or \n",
        "      (frase_mod[i]=='por' and frase_mod[i+1] == 'que')):\n",
        "      porque = frase_mod[i]+' '+frase_mod[i+1]\n",
        "  return porque "
      ],
      "metadata": {
        "id": "YQydwIbtwjgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado"
      ],
      "metadata": {
        "id": "u3DerWnOnGAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase = \"Pedro, porque você está chorando?\"\n",
        "lista = avaliacao_atributos(frase)\n",
        "porque = palavra_porque(frase)\n",
        "caso = calculo_similaridade(lista)\n",
        "if (caso==porque):\n",
        "  print(\"Acertou! O uso dos porquês está correto.\")\n",
        "else:\n",
        "  print(\"O uso dos porquês está incorreto. Por favor, substituia o porquê que você digitou pelo '\",caso,\"'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQMOkX2ppfKZ",
        "outputId": "3e12cd18-a184-4b14-a3b2-2200e47bfaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acertou! O uso dos porquês está correto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste com qualquer frase"
      ],
      "metadata": {
        "id": "xmaWsALTxcmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Escreva a frase que você está com dúvida sobre o uso dos porquês. \n",
        "#@markdown Não esqueça da pontuação final!\n",
        "frase = \"Eu te amo porque voc\\xEA \\xE9 rico. \" #@param {type:\"string\"}\n",
        "\n",
        "lista = avaliacao_atributos(frase)\n",
        "porque = palavra_porque(frase)\n",
        "caso = calculo_similaridade(lista)\n",
        "# print(lista)\n",
        "# print(porque)\n",
        "# print(caso)\n",
        "if (caso==porque):\n",
        "  print(\"Acertou! O uso dos porquês está correto.\")\n",
        "else:\n",
        "  print(\"O uso dos porquês está incorreto. Por favor, substituia o porquê que você digitou pelo '\",caso,\"'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqB0Xfl-HAhC",
        "outputId": "910ad454-8e91-4880-f390-302d306add54",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acertou! O uso dos porquês está correto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências bibliográficas\n",
        "\n",
        "- LOPES, Alexandre. NOGUEIRA, Rodrigo. LOTUFO, Roberto. PEDRINI, Helio. Universidade Estadual de Campinas (UNICAMP). **Training Strategies for Portuguese-English and English-Portuguese Translation.** Disponível em: https://huggingface.co/unicamp-dl/translation-pt-en-t5. Acesso em 20 de fev. de 2022. \n",
        "\n",
        "- PORTELLA, Leticia. **https://leportella.com/pt-br/npl-com-spacy/.** Disponível em: https://leportella.com/pt-br/npl-com-spacy/. Acesso em 20 de fev. de 2022. Acesso em 20 de fev. de 2022. \n",
        "\n",
        "- RIBEIRO, Roberto. Universidade Federal de Lavras (UFLA). **USO DO PORQUE, PORQUÊ, POR QUE OU POR QUÊ.** Disponível em: https://www.ufla.br/dcom/2018/05/22/uso-do-porque-porque-por-que-ou-por-que/. Acesso em 20 de fev. de 2022.\n",
        "\n"
      ],
      "metadata": {
        "id": "jAPgNp_Px_qj"
      }
    }
  ]
}